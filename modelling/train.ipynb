{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('shortDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome bake sir</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bol diya ab bol diya ab kya kr sakte h</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avi yaha yoh  baj ne wale hai sir</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all the very best</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jai alak sir</td>\n",
       "      <td>irrelevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  comment       label\n",
       "0                        welcome bake sir  irrelevant\n",
       "1  bol diya ab bol diya ab kya kr sakte h  irrelevant\n",
       "2       avi yaha yoh  baj ne wale hai sir  irrelevant\n",
       "3                       all the very best  irrelevant\n",
       "4                            jai alak sir  irrelevant"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "irrelevant    10000\n",
       "feedbak       10000\n",
       "doubt         10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].replace({'irrelevant':'0', 'doubt':'1', 'feedbak':'2'}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df['comment'].to_list()\n",
    "labels = to_categorical(df['label'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(comments, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_length = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding = 'post', truncating = 'post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding = 'post', truncating = 'post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # Adjust output dimension based on your labels (binary or multi-class)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 80s 105ms/step - loss: 1.0988 - accuracy: 0.3383 - val_loss: 1.0988 - val_accuracy: 0.3335\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 82s 109ms/step - loss: 92268437504.0000 - accuracy: 0.3326 - val_loss: 1.0989 - val_accuracy: 0.3327\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 82s 110ms/step - loss: 234392128.0000 - accuracy: 0.3333 - val_loss: 1.0986 - val_accuracy: 0.3343\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 85s 114ms/step - loss: 1169772544.0000 - accuracy: 0.3304 - val_loss: 1.0989 - val_accuracy: 0.3343\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 84s 113ms/step - loss: 1.0986 - accuracy: 0.3303 - val_loss: 1.0986 - val_accuracy: 0.3325\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 85s 113ms/step - loss: 1.0982 - accuracy: 0.3380 - val_loss: 1.0988 - val_accuracy: 0.3325\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 84s 112ms/step - loss: 4436091469824.0000 - accuracy: 0.3358 - val_loss: 1.0987 - val_accuracy: 0.3342\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 84s 112ms/step - loss: 1.0985 - accuracy: 0.3326 - val_loss: 1.0987 - val_accuracy: 0.3335\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 87s 116ms/step - loss: 1.0983 - accuracy: 0.3375 - val_loss: 1.0987 - val_accuracy: 0.3325\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 87s 117ms/step - loss: 1.0982 - accuracy: 0.3335 - val_loss: 1.0986 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c693a27e90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_V1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM_V1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"LSTM_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6125    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'doubt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comment = ['fuck']\n",
    "test_comment = tokenizer.texts_to_sequences(test_comment)\n",
    "test_comment = pad_sequences(test_comment, maxlen=max_length, padding = 'post', truncating = 'post')\n",
    "print(test_comment)\n",
    "pred_comment = model.predict(test_comment)\n",
    "pred_comment = pred_comment.argmax()\n",
    "mapping = {0:'irrelevant', 1:'doubt', 2:'feedbak'}\n",
    "mapping[pred_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
