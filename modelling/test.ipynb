{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040929f2585742b1b032eae652d55e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hamma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hamma\\.cache\\huggingface\\hub\\models--hammadali1805--comments-classification. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c489725a6c9e4aec9b675f138a6e64f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/731k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f0b26f956b4441bd7602181d79612f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hammadali1805/comments-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['les', '##bi', '##an']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"lesbian\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token_id = tokenizer.cls_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "tokenized_comments = df.comment.map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tokenized_comments = [len(x) for x in tokenized_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.034789129993385"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len_tokenized_comments)/len(len_tokenized_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 25\n",
    "irrelevant = [(x, y) for x, y in zip(len_tokenized_comments, df.label) if x >= limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 44.75592263405752, Doubt: 31.9476965404203, Feedback: 47.3518995492595, Irrelevant: 20.7004039103202\n",
      "Total: 39.610746870844984, Doubt: 32.367117806089965, Feedback: 47.76979487900259, Irrelevant: 19.863087314907443\n",
      "Total: 35.12808085042279, Doubt: 32.715237962056584, Feedback: 48.2058453363166, Irrelevant: 19.07891670162681\n",
      "Total: 31.32331654407671, Doubt: 32.94928225663115, Feedback: 48.73127228245528, Irrelevant: 18.319445460913567\n",
      "Total: 27.952147343738744, Doubt: 33.2489777746535, Feedback: 49.05158576734268, Irrelevant: 17.69943645800382\n",
      "Total: 25.00867845189518, Doubt: 33.461664375040925, Feedback: 49.46114057487069, Irrelevant: 17.077195050088392\n",
      "Total: 22.427412118393732, Doubt: 33.70325482236468, Feedback: 49.71014704379189, Irrelevant: 16.586598133843435\n",
      "Total: 20.201798568219182, Doubt: 33.997438682380405, Feedback: 49.859775965762644, Irrelevant: 16.142785351856954\n",
      "Total: 18.240140951158327, Doubt: 34.21907822683448, Feedback: 50.03501086234448, Irrelevant: 15.74591091082105\n",
      "Total: 16.48381878082488, Doubt: 34.32471093098105, Feedback: 50.222513609091266, Irrelevant: 15.452775459927684\n",
      "Total: 14.946259096000054, Doubt: 34.44860755055983, Feedback: 50.526961589868314, Irrelevant: 15.024430859571858\n",
      "Total: 13.586525802838672, Doubt: 34.663870610070624, Feedback: 50.661653047942735, Irrelevant: 14.674476341986647\n",
      "Total: 12.35156572371739, Doubt: 34.90561035104464, Feedback: 50.638986106692116, Irrelevant: 14.455403542263232\n",
      "Total: 11.285589839988997, Doubt: 34.96126055541046, Feedback: 50.75592698993064, Irrelevant: 14.282812454658888\n",
      "Total: 10.30017618894791, Doubt: 35.02479969477299, Feedback: 50.7916825639069, Irrelevant: 14.183517741320106\n",
      "Total: 9.39990961310479, Doubt: 35.254154617984184, Feedback: 50.8169877713131, Irrelevant: 13.928857610702714\n",
      "Total: 8.581187736201262, Doubt: 35.3699958020074, Feedback: 50.887302980574745, Irrelevant: 13.742701217417853\n",
      "Total: 7.8580925745200645, Doubt: 35.48655969993749, Feedback: 50.83559074807251, Irrelevant: 13.677849551989999\n",
      "Total: 7.226694263052064, Doubt: 35.57348076313047, Feedback: 50.80436851407079, Irrelevant: 13.622150722798748\n",
      "Total: 6.653916437970356, Doubt: 35.70233290678216, Feedback: 50.71857466286052, Irrelevant: 13.579092430357317\n",
      "Total: 6.155151070560726, Doubt: 35.6318169725991, Feedback: 50.848629954775205, Irrelevant: 13.519553072625698\n",
      "Total: 5.681274848208965, Doubt: 35.88886326954116, Feedback: 50.88771039889325, Irrelevant: 13.2234263315656\n",
      "Total: 5.252264584711515, Doubt: 35.970819304152634, Feedback: 50.841750841750844, Irrelevant: 13.187429854096521\n",
      "Total: 4.847815977521172, Doubt: 35.99270418158481, Feedback: 50.77349185975816, Irrelevant: 13.233803958657028\n",
      "Total: 4.488888306686666, Doubt: 35.981615233092576, Feedback: 50.616473334792445, Irrelevant: 13.401911432114977\n",
      "Total: 4.164674443432868, Doubt: 36.085554769206574, Feedback: 50.53864905244948, Irrelevant: 13.375796178343949\n",
      "Total: 3.8545425964618114, Doubt: 36.032285471537804, Feedback: 50.54375531011045, Irrelevant: 13.423959218351742\n",
      "Total: 3.5954989946095353, Doubt: 35.94134256307496, Feedback: 50.541943710720474, Irrelevant: 13.516713726204571\n",
      "Total: 3.343987634024771, Doubt: 35.74576437175595, Feedback: 50.710018607384185, Irrelevant: 13.544217020859858\n",
      "Total: 3.1039383797166566, Doubt: 35.62987972146022, Feedback: 50.71745093901667, Irrelevant: 13.652669339523108\n",
      "Total: 2.9064626630075256, Doubt: 35.526760563380286, Feedback: 50.794366197183095, Irrelevant: 13.678873239436621\n",
      "Total: 2.704729592538496, Doubt: 35.54909795374743, Feedback: 50.81729022884126, Irrelevant: 13.633611817411309\n",
      "Total: 2.528540644628857, Doubt: 35.617148037818936, Feedback: 50.64110866468074, Irrelevant: 13.741743297500324\n",
      "Total: 2.3667612017527198, Doubt: 35.58876435588764, Feedback: 50.62958350629584, Irrelevant: 13.781652137816522\n",
      "Total: 2.2105490676395263, Doubt: 35.40740740740741, Feedback: 50.8, Irrelevant: 13.792592592592593\n",
      "Total: 2.0648165735506985, Doubt: 35.654242664551944, Feedback: 50.610626486915145, Irrelevant: 13.735130848532911\n",
      "Total: 1.9406983370121236, Doubt: 35.58893013837327, Feedback: 50.57374282821465, Irrelevant: 13.837327033412084\n",
      "Total: 1.8267322517471527, Doubt: 35.622086769451414, Feedback: 50.394406597346716, Irrelevant: 13.983506633201864\n",
      "Total: 1.7166960314913184, Doubt: 35.48264021365891, Feedback: 50.515070583746656, Irrelevant: 14.002289202594428\n",
      "Total: 1.6207418275182246, Doubt: 35.27985451606385, Feedback: 50.57587391392201, Irrelevant: 14.144271570014144\n",
      "Total: 1.531664887311121, Doubt: 35.172118879623696, Feedback: 50.58798375026726, Irrelevant: 14.239897370109045\n"
     ]
    }
   ],
   "source": [
    "for limit in range(10, 51):\n",
    "    irrelevant = [(x, y) for x, y in zip(len_tokenized_comments, df.label) if x >= limit]\n",
    "    d_tag = [y for x, y in irrelevant if y=='doubt']\n",
    "    f_tag = [y for x, y in irrelevant if y=='feedbak']\n",
    "    i_tag = [y for x, y in irrelevant if y=='irrelevant']\n",
    "\n",
    "    p_t = (len(irrelevant)/len(len_tokenized_comments))*100\n",
    "    p_d = (len(d_tag)/len(irrelevant))*100\n",
    "    p_f = (len(f_tag)/len(irrelevant))*100\n",
    "    p_i = (len(i_tag)/len(irrelevant))*100\n",
    "    print(f\"Total: {p_t}, Doubt: {p_d}, Feedback: {p_f}, Irrelevant: {p_i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OOV token is: 0\n"
     ]
    }
   ],
   "source": [
    "oov_token = tokenizer.unk_token_id\n",
    "print(f\"The OOV token is: {oov_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
